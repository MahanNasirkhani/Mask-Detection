{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahanNasirkhani/Mask-Detection/blob/main/MobileSAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7bxNhG13jJD",
        "outputId": "4199b4dd-041b-4c2e-d581-13ebfcc9caf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZW3IZ4D3qXZ",
        "outputId": "01c8ea82-f76f-4abc-b211-3692fbc8291f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyvIbQtQ3wA-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import itertools\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Install MobileSAM"
      ],
      "metadata": {
        "id": "Udy0yJGxE4yk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThZjtXTP3uup",
        "outputId": "7472b581-6285-4f0a-eec6-def9a2cb0688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Collecting git+https://github.com/ChaoningZhang/MobileSAM.git\n",
            "  Cloning https://github.com/ChaoningZhang/MobileSAM.git to /tmp/pip-req-build-v307648w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ChaoningZhang/MobileSAM.git /tmp/pip-req-build-v307648w\n",
            "  Resolved https://github.com/ChaoningZhang/MobileSAM.git to commit 01ea8d0f5590082f0c1ceb0a3e2272593f20154b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "--2023-08-20 08:15:55--  https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/weights/mobile_sam.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40728226 (39M) [application/octet-stream]\n",
            "Saving to: ‘mobile_sam.pt.1’\n",
            "\n",
            "mobile_sam.pt.1     100%[===================>]  38.84M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-08-20 08:15:56 (348 MB/s) - ‘mobile_sam.pt.1’ saved [40728226/40728226]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!pip install git+https://github.com/ChaoningZhang/MobileSAM.git\n",
        "!wget https://raw.githubusercontent.com/ChaoningZhang/MobileSAM/master/weights/mobile_sam.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load MobileSAM"
      ],
      "metadata": {
        "id": "DvD7I8jXFBvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQhW6QiL3yhn"
      },
      "outputs": [],
      "source": [
        "from mobile_sam import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = f\"{HOME}/mobile_sam.pt\"\n",
        "model_type = \"vit_t\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "sam.eval()\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "P8pkeQPkFXtT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k798afFz37yC"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/Dataset'\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "test_dir = os.path.join(base_dir, 'Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_wxLH1w3-px"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = os.listdir(folder)\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_folder = os.path.join(folder, class_name)\n",
        "        if not os.path.isdir(class_folder):\n",
        "            continue\n",
        "\n",
        "        for filename in tqdm(os.listdir(class_folder)):\n",
        "            img_path = os.path.join(class_folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            if img is not None:\n",
        "                images.append(image)\n",
        "                labels.append(class_name)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1gqeaUF4ATN",
        "outputId": "9d414cb3-3cb7-4c9f-8afa-ffc9cfb7d1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560/560 [00:05<00:00, 97.94it/s] \n",
            "100%|██████████| 560/560 [00:13<00:00, 43.06it/s]\n",
            "<ipython-input-12-88a220b4d37c>:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(images), np.array(labels)\n"
          ]
        }
      ],
      "source": [
        "X_train_data, y_train_data = load_images_from_folder(train_dir)\n",
        "X_test_data, y_test_data = load_images_from_folder(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Darkness to Reveal Image Features"
      ],
      "metadata": {
        "id": "x3z4wI9aFnZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw6vFKTH4DSH"
      },
      "outputs": [],
      "source": [
        "def delete_dark(extracted_image, face_points):\n",
        "\n",
        "  original_h = extracted_image.shape[0]\n",
        "  original_w = extracted_image.shape[1]\n",
        "\n",
        "  i = 0\n",
        "  x_1 = 0\n",
        "  y_1 = 0\n",
        "  x_2 = original_h -1\n",
        "  y_2 = original_w -1\n",
        "\n",
        "  while True:\n",
        "    if (extracted_image[0][i].all()!=0):\n",
        "      y_1 = i\n",
        "      break\n",
        "    if (extracted_image[original_h//4][i].all()!=0):\n",
        "      y_1 = i\n",
        "      break\n",
        "    if (extracted_image[original_h//2][i].all()!=0):\n",
        "      y_1 = i\n",
        "      break\n",
        "    if (extracted_image[3*(original_h//4)][i].all()!=0):\n",
        "      y_1 = i\n",
        "      break\n",
        "    if (extracted_image[original_h-1][i].all()!=0):\n",
        "      y_1 = i\n",
        "      break\n",
        "    i = i + original_w//20\n",
        "    if (i>=original_w):\n",
        "      break\n",
        "\n",
        "  i = 0\n",
        "  while True:\n",
        "    if (extracted_image[i][0].all()!=0):\n",
        "      x_1 = i\n",
        "      break\n",
        "    if (extracted_image[i][original_w//4].all()!=0):\n",
        "      x_1 = i\n",
        "      break\n",
        "    if (extracted_image[i][original_w//2].all()!=0):\n",
        "      x_1 = i\n",
        "      break\n",
        "    if (extracted_image[i][3*(original_w//4)].all()!=0):\n",
        "      x_1 = i\n",
        "      break\n",
        "    if (extracted_image[i][original_w-1].all()!=0):\n",
        "      x_1 = i\n",
        "      break\n",
        "    i = i + original_h//20\n",
        "    if (i>=original_h):\n",
        "      break\n",
        "\n",
        "\n",
        "  i = original_w -1\n",
        "  while True:\n",
        "    if (extracted_image[0][i].all()!=0):\n",
        "      y_2 = i\n",
        "      break\n",
        "    if (extracted_image[original_h//4][i].all()!=0):\n",
        "      y_2 = i\n",
        "      break\n",
        "    if (extracted_image[original_h//2][i].all()!=0):\n",
        "      y_2 = i\n",
        "      break\n",
        "    if (extracted_image[3*(original_h//4)][i].all()!=0):\n",
        "      y_2 = i\n",
        "      break\n",
        "    if (extracted_image[original_h-1][i].all()!=0):\n",
        "      y_2 = i\n",
        "      break\n",
        "    i = i - original_w//20\n",
        "    if (i<0):\n",
        "      break\n",
        "\n",
        "  i = original_h -1\n",
        "  while True:\n",
        "    if (extracted_image[i][0].all()!=0):\n",
        "      x_2 = i\n",
        "      break\n",
        "    if (extracted_image[i][original_w//4].all()!=0):\n",
        "      x_2 = i\n",
        "      break\n",
        "    if (extracted_image[i][original_w//2].all()!=0):\n",
        "      x_2 = i\n",
        "      break\n",
        "    if (extracted_image[i][3*(original_w//4)].all()!=0):\n",
        "      x_2 = i\n",
        "      break\n",
        "    if (extracted_image[i][original_w-1].all()!=0):\n",
        "      x_2 = i\n",
        "      break\n",
        "    i = i - original_h//20\n",
        "    if (i<0):\n",
        "      break\n",
        "\n",
        "  if (x_1 == x_2) or (y_1 == y_2) or (x_1 > x_2) or (y_1 > y_2):\n",
        "    y_1 = face_points[0][0]\n",
        "    y_2 = face_points[2][0]\n",
        "    x_1 = face_points[3][1]\n",
        "    x_2 = face_points[1][1]\n",
        "\n",
        "\n",
        "  return extracted_image[x_1:x_2, y_1:y_2]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading face_mesh and Defining Its Points"
      ],
      "metadata": {
        "id": "l9s5ZIH_GOV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqpZDtfW4BmF"
      },
      "outputs": [],
      "source": [
        "points = [212,200,432,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbJZn2kS4JPt"
      },
      "outputs": [],
      "source": [
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "face_mesh_images = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Facial Landmark Detection: Utilizing face_mesh to Identify Facial Points"
      ],
      "metadata": {
        "id": "f2blXibqGh2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OhNzONY4Ktz"
      },
      "outputs": [],
      "source": [
        "def face_points(image):\n",
        "\n",
        "        for _ in range(5):\n",
        "              face_mesh_results = face_mesh_images.process(image)\n",
        "\n",
        "        FACEMESH_FACE_INDEXES_total = list(set(itertools.chain(*mp_face_mesh.FACEMESH_TESSELATION)))\n",
        "        list_of_points_face = []\n",
        "        if face_mesh_results.multi_face_landmarks:\n",
        "\n",
        "                for face_landmarks in face_mesh_results.multi_face_landmarks:\n",
        "\n",
        "\n",
        "                    for FACEMESH_FACE_INDEX in FACEMESH_FACE_INDEXES_total:\n",
        "\n",
        "                        land = face_landmarks.landmark[FACEMESH_FACE_INDEX]\n",
        "                        list_of_points_face.append((land.x,land.y))\n",
        "\n",
        "\n",
        "\n",
        "                list_of_points_face = np.array(list_of_points_face)\n",
        "                return list_of_points_face\n",
        "        return \"No Face Was Detected\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isolating and Highlighting the Face in Images"
      ],
      "metadata": {
        "id": "IkkuKDWtG1Dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_X9aNR74MMk"
      },
      "outputs": [],
      "source": [
        "def keep_face(image,list_of_points_face,original_w,original_h):\n",
        "  list_of_points_face = list_of_points_face *[original_w , original_h]\n",
        "  list_of_points_face = np.round(list_of_points_face)\n",
        "  list_of_points_face = np.array(list_of_points_face ,np.int32)\n",
        "\n",
        "  convexhull = cv2.convexHull(list_of_points_face)\n",
        "  mask = np.zeros(image.shape[0:2], np.uint8)\n",
        "  cv2.fillConvexPoly(mask, convexhull, 255)\n",
        "  face = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "  return face"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using MobileSAM for segmentation"
      ],
      "metadata": {
        "id": "OxcciqghHTIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78NEO_Hc4Nla"
      },
      "outputs": [],
      "source": [
        "def segment(image,label):\n",
        "  segment_part = []\n",
        "  labels = []\n",
        "  for i in tqdm(range(len(image))):\n",
        "        original_h = image[i].shape[0]\n",
        "        original_w = image[i].shape[1]\n",
        "\n",
        "        list_of_points_face = face_points(image[i])\n",
        "\n",
        "        input_points = []\n",
        "        if type(list_of_points_face) != str:\n",
        "                for j in points:\n",
        "                  input_points.append((list_of_points_face[j][0],list_of_points_face[j][1]))\n",
        "\n",
        "                input_points = np.array(input_points)\n",
        "                input_points = input_points*[original_w , original_h]\n",
        "                input_points = np.round(input_points)\n",
        "                input_points = np.array(input_points, dtype=np.int16)\n",
        "                input_label = np.ones((len(input_points)),dtype=np.int16)\n",
        "\n",
        "                face = keep_face(image[i],list_of_points_face,original_w,original_h)\n",
        "\n",
        "                predictor.set_image(face)\n",
        "                masks, scores, logits = predictor.predict(\n",
        "                       point_coords=input_points,\n",
        "                      point_labels=input_label,\n",
        "                     multimask_output=True,\n",
        "                                    )\n",
        "\n",
        "                max_score = masks[int(np.argmax(scores))]\n",
        "                extracted_image = face * max_score[:, :, np.newaxis]\n",
        "\n",
        "                result = delete_dark(extracted_image,input_points)\n",
        "\n",
        "                segment_part.append(result)\n",
        "                labels.append(label[i])\n",
        "\n",
        "  return segment_part,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01MVRB6s4Qw2",
        "outputId": "59f9ad90-4d58-471b-f584-7ad6bf85c341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1120/1120 [06:48<00:00,  2.74it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train_keep,y_train_keep = segment(X_train_data,y_train_data)\n",
        "X_test_keep,y_test_keep = segment(X_test_data,y_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Processed Data: Preserving Enhanced Images Generated by the Code"
      ],
      "metadata": {
        "id": "6AK2ogEYHl4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir_mask = '/content/drive/MyDrive/Mask Dataset/Train/Mask'\n",
        "train_dir_non_mask = '/content/drive/MyDrive/Mask Dataset/Train/No Mask'\n",
        "os.makedirs(train_dir_mask, exist_ok=True)\n",
        "os.makedirs(train_dir_non_mask, exist_ok=True)\n",
        "\n",
        "for idx, (image, label) in tqdm(enumerate(zip(X_train_keep, y_train_keep))):\n",
        "    if label == \"Mask\":\n",
        "      image_path = os.path.join(train_dir_mask, f'image_{idx}.jpg')\n",
        "    else:\n",
        "      image_path = os.path.join(train_dir_non_mask, f'image_{idx}.jpg')\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(image_path, image_rgb)"
      ],
      "metadata": {
        "id": "r9tmfpmemF5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir_mask = '/content/drive/MyDrive/Mask Dataset/Test/Mask'\n",
        "test_dir_non_mask = '/content/drive/MyDrive/Mask Dataset/Test/No Mask'\n",
        "os.makedirs(test_dir_mask, exist_ok=True)\n",
        "os.makedirs(test_dir_non_mask, exist_ok=True)\n",
        "\n",
        "for idx, (image, label) in tqdm(enumerate(zip(X_test_keep, y_test_keep))):\n",
        "    if label == \"Mask\":\n",
        "      image_path = os.path.join(test_dir_mask, f'image_{idx}.jpg')\n",
        "    else:\n",
        "      image_path = os.path.join(test_dir_non_mask, f'image_{idx}.jpg')\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(image_path, image_rgb)"
      ],
      "metadata": {
        "id": "s0Eg6swnnENb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de457cd0-8f6f-44a3-8acd-5e30c6bd580b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1026it [05:32,  3.09it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6pD0sJIrHazez9f4tU0ym",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}